{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-JY50zmDEa_q"
   },
   "source": [
    "# PART 2 TensorFlow\n",
    "# 5. Workshop 3 - RNN 序列資料處理\n",
    "2019/09/23\n",
    "\n",
    "> [ Reference ] :\n",
    "1. Tom Hope, Yehezkel S. Resheff, and Itay Lieder, \"**`Learning TensorFlow : A Guide to Building Deep Learning Systems`**\", Chapter 5, O'Reilly, 2017.\n",
    "      [ Code ] : https://github.com/giser-yugang/Learning_TensorFlow\n",
    "2. Victor Chou, \"**`An Introduction to Recurrent Neural Networks for Beginners`**\" Towards Data Science, 2019/07/25. https://towardsdatascience.com/an-introduction-to-recurrent-neural-networks-for-beginners-664d717adbd\n",
    "3. Andrej Karpathy, \"**`The Unreasonable Effectiveness of Recurrent Neural Networks`**\" Andrej Karpathy blog, 2015/05/21. https://towardsdatascience.com/an-introduction-to-recurrent-neural-networks-for-beginners-664d717adbd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9OniZkfWEa_s"
   },
   "source": [
    "# Introduction to Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "![title](./Fig_1_Sequence_Data.png)\n",
    "\n",
    "**Figure 1. The ubiquity of sequence data.** (from Ref. 1, Chapter 5)\n",
    "\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "chA4xaicEa_u"
   },
   "source": [
    "+ The basic idea behind RNN models is that each new element in the sequence contributes some new information, which updates the current state of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mk503JqvEa_v"
   },
   "source": [
    "+ A fundamental mathematical construct in statistics and probably, which is often  used as building block for modelling sequential pattern via machine learning is the **Markov chain model**. \n",
    "\n",
    "+ We tend to view our data sequences as \"*chains*\", with each node in the chain dependent in some way on the previous node, so that \"*history*\" is not erased but carried on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oKKiJwN9Ea_w"
   },
   "source": [
    "+ RNN models are the based on this notion of *chain structure*. \n",
    "\n",
    "\n",
    "+ As the name implie, recurrent neural nets apply some form of \"*loop*.\" \n",
    "    + At some point in time t, the network observes an input `x(t)` (a word in a sentence) and update its \"*state vector*\" to `h(t)` from the previous vector `h(t-1)`. \n",
    "    + When we process new input (the next word), it will be done in some manner that is dependent on `h(t)` and thus on the history of the sequence (the previous words we've seen affect our understanding of the current word).\n",
    "    \n",
    "    \n",
    "+ Recurrent structure can simply be viewed as one long unrolled chain, with each node in the chain performing the same kind of processing \"step\" based on the \"message\" it obtains from the output of the previous node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./Fig_2_RNN_operation.png)\n",
    "\n",
    "**Figure 2. Recurrent neural networks updating with new information received over\n",
    "time.** (from Ref. 1, Chapter 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./Fig_3_Intro_to_RNNs.png)\n",
    "\n",
    "\n",
    "**Figure 2. Different Recurrent Neural Networks.** (from Ref. 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bQGZ7C7pEa_x"
   },
   "source": [
    "--------------\n",
    "# Vanilla RNN Implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JPiv-9iAEa_y"
   },
   "source": [
    "We introduce some powerful, fairly low-level tools that Tensorflow provides for working\n",
    "with sequence data, which you can use to implement your own systems.\n",
    "\n",
    "We begin with our basic model mathematically. This mainly consists of defining the\n",
    "recurrence structure - the RNN update step.\n",
    "\n",
    "The update step for our simple vanilla RNN is\n",
    "\n",
    "`h(t) = tanh(W(x)x(t) + W(h)h(t-1) + b)`\n",
    "\n",
    "where `W(h)`,`W(x)` and `b` are weight and bias variables. `tanh(.)` is the hyperbolic tangent function that has its range in [-1,1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zTNOOHp-Ea_y"
   },
   "source": [
    "### MNIST image as sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wxrIaIoQEa_z"
   },
   "source": [
    "+ From the previous chapter the architecture of convolutional neural networks makes use of the spatial structure of images, it is revealing to look at the structure of images from different angles by trying to capture in some sense the \"generative process\" that created each image. \n",
    "+ Intuitively, this all comes down to the notion that nearby areas in images are somehow related, and trying to model this structure.\n",
    "\n",
    "\n",
    "+ In our MNIST data, this just means that each 28 * 28 pixel image can be viewed as sequence of lengh 28, each element in the sequence a vector of 28 pixels. \n",
    "+ Then the temporal dependencies in the RNN can be imaged as a scanner head, scanning the image from top to buttom(rows) or left to right (columns)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./Fig_4_MNIST_image_as_sequence_data.png)\n",
    "\n",
    "**Figure 3. An image as a sequence of pixel columns.** (from Ref 1, Chapter 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s4VxXz0TEa_0"
   },
   "source": [
    "We start by loading data, defining some parameters, and creating placeholders for\n",
    "our data:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "0MqHHGWnEa_1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data\\train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# for the old-version usage of TensorFlow, such as tensorflow.examples.tutorials.mnist\n",
    "old_v = tf.logging.get_verbosity()          \n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot=True)\n",
    "\n",
    "#Define some parameters\n",
    "element_size = 28\n",
    "time_steps = 28\n",
    "num_classes = 10\n",
    "batch_size = 128\n",
    "hidden_layer_size = 128\n",
    "\n",
    "# Where to save TensorBoard model summaries\n",
    "LOG_DIR = \"logs/RNN_with_summaries\"\n",
    "\n",
    "# Create placeholders for inputs, labels\n",
    "_inputs = tf.placeholder(tf.float32, shape=[None, time_steps, element_size], name=\"inputs\")\n",
    "\n",
    "y = tf.placeholder(tf.float32, shape=[None, num_classes], name=\"labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 16
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1341,
     "status": "ok",
     "timestamp": 1531006041430,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "Alp4B2tHEa_9",
    "outputId": "78ca46c0-b109-4296-bf5f-ac10aca28999"
   },
   "outputs": [],
   "source": [
    "batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "# Reshape data to 28 sequence of 28 pixels\n",
    "batch_x = batch_x.reshape((batch_size, time_steps, element_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 16
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 738,
     "status": "ok",
     "timestamp": 1531006043166,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "h8AmjqDiEa__",
    "outputId": "01865c9b-f699-46a4-e58c-7b7dbe8aa150"
   },
   "outputs": [],
   "source": [
    "#This helper function taken from official TensorFlow documentation, \n",
    "# simply add some ops that take care of logging summaries\n",
    "def variable_summaries(var):\n",
    "    with tf.name_scope('summaries'):\n",
    "      mean = tf.reduce_mean(var)\n",
    "      tf.summary.scalar('mean', mean)\n",
    "      with tf.name_scope('stddev'):\n",
    "        stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "      tf.summary.scalar('stddev', stddev)\n",
    "      tf.summary.scalar('max', tf.reduce_max(var))\n",
    "      tf.summary.scalar('min', tf.reduce_min(var))\n",
    "      tf.summary.histogram('histogram', var)\n",
    "      \n",
    "\n",
    "# Weights and bias for input and hidden layer\n",
    "with tf.name_scope('rnn_weights'):\n",
    "        with tf.name_scope(\"W_x\"):\n",
    "            Wx = tf.Variable(tf.zeros([element_size, hidden_layer_size]))\n",
    "            variable_summaries(Wx)\n",
    "        with tf.name_scope(\"W_h\"):\n",
    "            Wh = tf.Variable(tf.zeros([hidden_layer_size, hidden_layer_size]))\n",
    "            variable_summaries(Wh)\n",
    "        with tf.name_scope(\"Bias\"):\n",
    "            b_rnn = tf.Variable(tf.zeros([hidden_layer_size])) \n",
    "            variable_summaries(b_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 16
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 914,
     "status": "ok",
     "timestamp": 1531006045126,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "vF98FVFrEbAC",
    "outputId": "f1cdf177-7fc4-432b-bfce-46a8321be4b7"
   },
   "outputs": [],
   "source": [
    "def rnn_step(previous_hidden_state,x):\n",
    "    \n",
    "        current_hidden_state = tf.tanh(\n",
    "            tf.matmul(previous_hidden_state, Wh) +\n",
    "            tf.matmul(x, Wx) + b_rnn)\n",
    "\n",
    "        return current_hidden_state\n",
    "           \n",
    "# Processing inputs to work with scan function\n",
    "# Current input shape: (batch_size, time_steps, element_size)\n",
    "processed_input = tf.transpose(_inputs, perm=[1, 0, 2])\n",
    "# Current input shape now: (time_steps,batch_size, element_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "## To demonstrate the use of tf.scan function, consider the following simple example\n",
    "## (which is separate from the overall RNN code in this section):\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "elems = np.array([\"T\",\"e\",\"n\",\"s\",\"o\",\"r\", \" \", \"F\",\"l\",\"o\",\"w\"])\n",
    "scan_sum = tf.scan(lambda a, x: a + x, elems)\n",
    "\n",
    "sess=tf.InteractiveSession()\n",
    "sess.run(scan_sum)\n",
    "\n",
    "## [OUTPUT] :\n",
    "## array([b'T', b'Te', b'Ten', b'Tens', b'Tenso', b'Tensor', b'Tensor ',\n",
    "##        b'Tensor F', b'Tensor Fl', b'Tensor Flo', b'Tensor Flow'],\n",
    "##        dtype=object)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 16
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 692,
     "status": "ok",
     "timestamp": 1531006047139,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "_UzQm8GREbAF",
    "outputId": "737db7b9-3c6d-4283-efa5-d921257f7465"
   },
   "outputs": [],
   "source": [
    "initial_hidden = tf.zeros([batch_size,hidden_layer_size])\n",
    "# Getting all state vectors across time\n",
    "all_hidden_states = tf.scan(rnn_step,\n",
    "                            processed_input,\n",
    "                            initializer=initial_hidden,\n",
    "                            name='states')\n",
    "\n",
    "\n",
    "# Weights for output layers\n",
    "with tf.name_scope('linear_layer_weights') as scope:\n",
    "    with tf.name_scope(\"W_linear\"):\n",
    "        Wl = tf.Variable(tf.truncated_normal([hidden_layer_size,\n",
    "                                              num_classes],\n",
    "                                              mean=0,stddev=.01))\n",
    "        variable_summaries(Wl)\n",
    "    with tf.name_scope(\"Bias_linear\"):\n",
    "        bl = tf.Variable(tf.truncated_normal([num_classes],\n",
    "                                             mean=0,stddev=.01))\n",
    "        variable_summaries(bl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 16
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 883,
     "status": "ok",
     "timestamp": 1531006082619,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "Sm7QFsMgEbAK",
    "outputId": "4313b302-32f0-49bb-853c-81c40d761e34"
   },
   "outputs": [],
   "source": [
    "#Apply linear layer to state vector    \n",
    "def get_linear_layer(hidden_state):\n",
    "    return tf.matmul(hidden_state, Wl) + bl\n",
    "\n",
    "with tf.name_scope('linear_layer_weights') as scope:\n",
    "    #Iterate across time, apply linear layer to all RNN outputs\n",
    "    all_outputs = tf.map_fn(get_linear_layer, all_hidden_states)\n",
    "    #Get Last output -- h_28\n",
    "    output = all_outputs[-1]\n",
    "    tf.summary.histogram('outputs', output)\n",
    "\n",
    "with tf.name_scope('cross_entropy'):\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=output, labels=y))\n",
    "    tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "\n",
    "with tf.name_scope('train'):\n",
    "    #Using RMSPropOptimizer\n",
    "    train_step = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cross_entropy)\n",
    "\n",
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(output,1))\n",
    "\n",
    "    accuracy = (tf.reduce_mean(tf.cast(correct_prediction, tf.float32)))*100\n",
    "    tf.summary.scalar('accuracy', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 274007,
     "status": "ok",
     "timestamp": 1531006358674,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "RB-Kcw2QEbAO",
    "outputId": "aeb32554-914f-40d7-96c5-3a97d9eaa856"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Minibatch Loss= 2.302437, Training Accuracy= 7.81250\n",
      "Iter 1000, Minibatch Loss= 1.118892, Training Accuracy= 64.06250\n",
      "Iter 2000, Minibatch Loss= 0.614068, Training Accuracy= 81.25000\n",
      "Iter 3000, Minibatch Loss= 0.441066, Training Accuracy= 83.59375\n",
      "Iter 4000, Minibatch Loss= 0.272647, Training Accuracy= 90.62500\n",
      "Iter 5000, Minibatch Loss= 0.100507, Training Accuracy= 96.87500\n",
      "Iter 6000, Minibatch Loss= 0.102014, Training Accuracy= 96.87500\n",
      "Iter 7000, Minibatch Loss= 0.066492, Training Accuracy= 97.65625\n",
      "Iter 8000, Minibatch Loss= 0.059286, Training Accuracy= 98.43750\n",
      "Iter 9000, Minibatch Loss= 0.102746, Training Accuracy= 96.87500\n",
      "Test Accuracy: 97.65625\n"
     ]
    }
   ],
   "source": [
    "# Merge all the summaries\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "#Get a small test set  \n",
    "test_data = mnist.test.images[:batch_size].reshape((-1, time_steps,\n",
    "                                                     element_size))\n",
    "test_label = mnist.test.labels[:batch_size]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #Write summaries to LOG_DIR -- used by TensorBoard\n",
    "    train_writer = tf.summary.FileWriter(LOG_DIR + '/train',\n",
    "                                         graph=tf.get_default_graph())\n",
    "    test_writer = tf.summary.FileWriter(LOG_DIR + '/test',\n",
    "                                        graph=tf.get_default_graph())\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for i in range(10000):\n",
    "        \n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            # Reshape data to get 28 sequences of 28 pixels\n",
    "            batch_x = batch_x.reshape((batch_size, time_steps,\n",
    "                                       element_size))\n",
    "            summary,_ =sess.run([merged,train_step],\n",
    "                                feed_dict={_inputs:batch_x, y:batch_y})\n",
    "            #Add to summaries\n",
    "            train_writer.add_summary(summary, i)\n",
    "            \n",
    "            if i % 1000 == 0:\n",
    "                acc,loss, = sess.run([accuracy,cross_entropy],\n",
    "                                     feed_dict={_inputs: batch_x,\n",
    "                                                y: batch_y})\n",
    "                print (\"Iter \" + str(i) + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.5f}\".format(acc))   \n",
    "            if i % 100 == 0:\n",
    "                # Calculate accuracy for 128 mnist test images and\n",
    "                #add to summaries\n",
    "                summary, acc = sess.run([merged, accuracy],\n",
    "                                        feed_dict={_inputs: test_data,\n",
    "                                                   y: test_label})\n",
    "                test_writer.add_summary(summary, i)\n",
    "\n",
    "    test_acc = sess.run(accuracy, feed_dict={_inputs: test_data,\n",
    "                                             y: test_label})\n",
    "    print (\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fF1eSWhwEbAR"
   },
   "source": [
    "## Visualizing the model with TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vDap5fIIEbAS"
   },
   "source": [
    "TensorBoard is an interactive browser-based tool that allows us to visualize the learning process.\n",
    "To run TensorBoard, go to the command terminal and tell TensorBoard where the relevant summaries you logged are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 16
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 718,
     "status": "ok",
     "timestamp": 1531006365649,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "la8bxfR7EbAT",
    "outputId": "a9cc47e8-60cc-4e93-bac9-aabd4ad68879"
   },
   "outputs": [],
   "source": [
    "#tensorboard --logdir=LOG_DIR   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 16
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 717,
     "status": "ok",
     "timestamp": 1531006376710,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "lpcHM2ySEbAa",
    "outputId": "a08bfaf5-6a06-4ed9-f336-920aa1006e04"
   },
   "outputs": [],
   "source": [
    "#If you are on Windows use:tensorboard --logdir=rnn_demo:LOG_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vAlmhWe4EbAf"
   },
   "source": [
    "TensorBoard allows us to assign names to individual log directories by putting a colon between the name and the path, which may\n",
    "be useful when working with multiple log directories. In such a case, we pass a comma-seperated list of log directories as follows-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 16
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 704,
     "status": "ok",
     "timestamp": 1531006383352,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "jaQWeUyREbAg",
    "outputId": "225b7c2e-4e8e-40df-a430-497c761c4706"
   },
   "outputs": [],
   "source": [
    "#tensorboard --logdir=rnn_demo1:LOG_DIR1, rnn_demo2:LOG_DIR2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kFdvE8YbEbAk"
   },
   "source": [
    "To start the tensorboard, go to the directory containing the log and run the tensorboard command in the terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 16
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 729,
     "status": "ok",
     "timestamp": 1531006385483,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "TrQ2SoAHEbAl",
    "outputId": "76e13c17-0fe0-465a-879f-0fa8efa0ce9a"
   },
   "outputs": [],
   "source": [
    "#Starting TensorBoard b'39' on port 6006\n",
    "#(You can navigate to http://10.100.102.4:6006)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xTLMtnLLEbAn"
   },
   "source": [
    "# TensorFlow Built-in RNN Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1265,
     "status": "ok",
     "timestamp": 1531006388393,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "xVz05MIfEbAp",
    "outputId": "7f873ce6-4d71-4483-a9ce-1bba9fe3aa86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 100
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 118193,
     "status": "ok",
     "timestamp": 1531006507096,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": -60
    },
    "id": "kjePs0RxEbAs",
    "outputId": "014150ff-0506-4ef3-e8ed-2f475bd6f81b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Minibatch Loss= 2.305105, Training Accuracy= 6.25000\n",
      "Iter 1000, Minibatch Loss= 0.230711, Training Accuracy= 94.53125\n",
      "Iter 2000, Minibatch Loss= 0.102143, Training Accuracy= 97.65625\n",
      "Iter 3000, Minibatch Loss= 0.075217, Training Accuracy= 96.87500\n",
      "Testing Accuracy: 98.4375\n"
     ]
    }
   ],
   "source": [
    "element_size = 28; time_steps= 28; num_classes =10\n",
    "batch_size = 128; hidden_layer_size = 128\n",
    "\n",
    "_inputs = tf.placeholder(tf.float32,shape=[None, time_steps,\n",
    "element_size],\n",
    "name='inputs')\n",
    "y = tf.placeholder(tf.float32, shape=[None, num_classes],name='inputs')\n",
    "\n",
    "# TensorFlow built-in functions\n",
    "# 內建 Simple RNN 架構 (hidden layer部分) # tf.contrib 在 tensorflow2.0 無法執行\n",
    "rnn_cell = tf.contrib.rnn.BasicRNNCell(hidden_layer_size)\n",
    "# 執行\n",
    "outputs, _ = tf.nn.dynamic_rnn(rnn_cell, _inputs, dtype=tf.float32)\n",
    "\n",
    "Wl = tf.Variable(tf.truncated_normal([hidden_layer_size, num_classes],\n",
    "mean=0,stddev=.01))\n",
    "bl = tf.Variable(tf.truncated_normal([num_classes],mean=0,stddev=.01))\n",
    "\n",
    "\n",
    "\n",
    "def get_linear_layer(vector):\n",
    "    return tf.matmul(vector, Wl) + bl\n",
    "\n",
    "last_rnn_output = outputs[:,-1,:]\n",
    "final_output = get_linear_layer(last_rnn_output)\n",
    "softmax = tf.nn.softmax_cross_entropy_with_logits(logits=final_output,\n",
    "labels=y)\n",
    "cross_entropy = tf.reduce_mean(softmax)\n",
    "train_step = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(final_output,1))\n",
    "accuracy = (tf.reduce_mean(tf.cast(correct_prediction, tf.float32)))*100\n",
    "sess=tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "test_data = mnist.test.images[:batch_size].reshape((-1,time_steps, element_size))\n",
    "test_label = mnist.test.labels[:batch_size]\n",
    "\n",
    "\n",
    "for i in range(3001):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        batch_x = batch_x.reshape((batch_size, time_steps, element_size))\n",
    "        sess.run(train_step,feed_dict={_inputs:batch_x,y:batch_y})\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "                acc = sess.run(accuracy, feed_dict={_inputs: batch_x,y: batch_y})\n",
    "                loss = sess.run(cross_entropy,feed_dict={_inputs:batch_x,y:batch_y})\n",
    "                print(\"Iter \" + str(i) + \", Minibatch Loss= \" + \\\n",
    "                          \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                          \"{:.5f}\".format(acc))\n",
    "print(\"Testing Accuracy:\",\n",
    "        sess.run(accuracy, feed_dict={_inputs: test_data, y: test_label}))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Chapter5.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
