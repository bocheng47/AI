{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2 TensorFlow\n",
    "# 6. Workshop 4 :  自然語言處理 (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## < NLP > :  Text generation with LSTM - `Generative Deep Learning`\n",
    " \n",
    " \n",
    "> **[ Reference ] :**  \n",
    " + FRANÇOIS CHOLLET, **Deep Learning with Python**, Chapter 8, Section 1, Manning, 2018. \n",
    "(https://tanthiamhuat.files.wordpress.com/2018/03/deeplearningwithpython.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macmini1/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.2.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Implementing character-level LSTM text generation\n",
    "\n",
    "\n",
    "+ Let's put these ideas in practice in a Keras implementation. The first thing we need is a lot of text data that we can use to learn a language model. \n",
    "+ You could use any sufficiently large text file or set of text files -- Wikipedia, the Lord of the Rings, etc. \n",
    "> + In this example we will use some of the writings of Nietzsche, the late-19th century German philosopher (translated to English). \n",
    " + The language model we will learn will thus be specifically a model of Nietzsche's writing style and topics of choice, rather than a more generic model of the English language.\n",
    " \n",
    "+ **The following diagram is from the book - `Deep Learning with Python`, Chapter 8, Section 8.1.2.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./character-level neural language model.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "+ **Let's start by downloading the corpus and converting it to lowercase:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "path = keras.utils.get_file(\n",
    "    'nietzsche.txt',\n",
    "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
    "text = open(path).read().lower()\n",
    "print('Corpus length:', len(text))  ## Corpus length (= len(text)): 600893"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "+ **Next, we will extract partially-overlapping sequences of length `maxlen`, one-hot encode them and pack them in a 3D Numpy array `x` of shape `(sequences, maxlen, unique_characters)`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 200278\n"
     ]
    }
   ],
   "source": [
    "# maxlen : Length of extracted character sequences\n",
    "maxlen = 60   ## You’ll extract sequences of 60 characters.\n",
    "\n",
    "# step : sampling a new sequence every `step` characters\n",
    "step = 3      ## You’ll sample a new sequence every three characters.\n",
    "\n",
    "# This holds our extracted sequences\n",
    "sentences = []   ## Holding the extracted sequences...\n",
    "\n",
    "# This holds the targets (the follow-up characters)\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('Number of sequences:', len(sentences))  ##  len(sentences) = 200278 => Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'preface\\n\\n\\nsupposing that truth is a woman--what then? is the'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0:maxlen]  ## sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0 + maxlen]  ## next_chars[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'face\\n\\n\\nsupposing that truth is a woman--what then? is there '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[3 : 3+maxlen]  ## sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[3 + maxlen]  ## next_chars[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'preface\\n\\n\\nsupposing that truth is a woman--what then? is there not ground\\nfor suspecting that all philosophers, in so far as they have been\\ndogmatists, have failed to understand women--that the terrible\\nseriousness and clumsy importunity with which they have usually paid\\ntheir addresses to truth, have been unskilled and unseemly methods for\\nwinning a woman? certainly she has never allowed herself to be won; and\\nat present every kind of dogma stands with sad and discouraged mien--if,\\nindeed, it stands at all! for there are scoffers who maintain that it\\nhas fallen, that all dogma lies on the ground--nay more, that it is at\\nits last gasp. but to speak seriously, there are good grounds for hoping\\nthat all dogmatizing in philosophy, whatever solemn, whatever conclusive\\nand decided airs it has assumed, may have been only a noble puerilism\\nand tyronism; and probably the time is at hand when it will be once\\nand again understood what has actually sufficed for the basis of such\\nimposing and abso'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique characters: 57\n"
     ]
    }
   ],
   "source": [
    "# List of unique characters in the corpus\n",
    "chars = sorted(list(set(text)))\n",
    "print('Unique characters:', len(chars))\n",
    "\n",
    "# Dictionary mapping unique characters to their index in `chars`\n",
    "char_indices = dict((char, chars.index(char)) for char in chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ **Simultaneously, we prepare a array `y` containing the corresponding targets: the one-hot encoded characters that come right after each extracted sequence.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n"
     ]
    }
   ],
   "source": [
    "# Next, one-hot encode the characters into binary arrays.\n",
    "print('Vectorization...')\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the network with `Keras/TensorFlow`\n",
    "\n",
    "+ **Our network is a single `LSTM` layer followed by a `Dense` classifier and softmax over all possible characters.**\n",
    "\n",
    "[ NOTE ] : Recurrent neural networks are not the only way to do sequence data generation; `1D convnets` also have proven extremely successful at it in \n",
    "recent times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(layers.Dense(len(chars), activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our targets are one-hot encoded, we will use `categorical_crossentropy` as the loss to train the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the language model and sampling from it\n",
    "\n",
    "\n",
    "### The importance of the sampling strategy :\n",
    "> + A more interesting approach makes slightly more sur- prising choices: it introduces `randomness` in the sampling process, by sampling from the probability distribution for the next character. This is called `stochastic sampling` (recall that _stochasticity_ is what we call _randomness_ in this field).\n",
    "+ In order to control the amount of stochasticity in the sampling process, we’ll intro- duce a parameter called the `softmax temperature` that characterizes the entropy of the probability distribution used for sampling: it characterizes how surprising or predict- able the choice of the next character will be. _Given a temperature value, a new probability distribution is computed from the original one_ (the softmax output of the model) by reweighting it in the following way.\n",
    "\n",
    "Given a trained model and a seed text snippet, we generate new text by repeatedly:\n",
    "\n",
    "+ Drawing from the model a probability distribution over the next character given the text available so far\n",
    "+ Reweighting the distribution to a certain `temperature`\n",
    "+ Sampling the next character at random according to the reweighted distribution\n",
    "+ Adding the new character at the end of the available text\n",
    "\n",
    "### [ NOTE ] : `temperature` is a factor quantifying the entropy of the output distribution.\n",
    "\n",
    "**This is the code we use to `reweight the original probability distribution` coming out of the model, and draw a character index from it (the \"sampling function\"):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Original_distribution is a 1D Numpy array of probability values that must sum to 1.\n",
    "##  'temperature' is a factor quantifying the entropy of the output distribution.\n",
    "def sample(preds, temperature=1.0):  \n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    ##-------------------------------------------------------------------\n",
    "    ##  Computeing a reweighted version of the original distribution. \n",
    "    ##  The sum of the distribution may no longer be 1, so you divide it \n",
    "    ##  by its sum to obtain the new distribution.\n",
    "    ##-------------------------------------------------------------------\n",
    "    preds = exp_preds / np.sum(exp_preds) \n",
    "    \n",
    "    ##------------------------------------------------------\n",
    "    ##  Draw samples from a multinomial distribution.\n",
    "    ##  The multinomial distribution is a multivariate \n",
    "    ##  generalisation of the binomial distribution. \n",
    "    ##------------------------------------------------------\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Finally, this is the loop where we repeatedly train and generated text.** \n",
    " + **We start generating text using a range of different temperatures after every epoch.** \n",
    "\n",
    " + **This allows us to see how the generated text evolves as the model starts converging, as well as the impact of temperature in the sampling strategy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "Epoch 1/1\n",
      "200278/200278 [==============================] - 239s 1ms/step - loss: 1.9297\n",
      "--- Generating with seed: \" who have asked ourselves the question a hundred times, have\"\n",
      "------ temperature: 0.2\n",
      " who have asked ourselves the question a hundred times, have the soul and the soul and everyther the soul and the such the soul and the soul and the soul and the soul and the soul and the soul and the soul to the soul that whole is and the soul and the soul and the soul the soul and the soul and the such the for the such as and the soul and the spirit to be dot the soul and the soul and the such a man be and the soul and the soul and the such and the for t\n",
      "------ temperature: 0.5\n",
      " man be and the soul and the soul and the such and the for the \"last in such as these the love and wooders of the spirit and interranged. the sangerous speries of the fact is and the for the it is doing of the spories of the for to the bold of the will in the that disto who and only the inturtion, that the soul the antard that soul of which the gart of the would and the soul is power to and in evelies of hand the boding of the the world of the dangerous is\n",
      "------ temperature: 1.0\n",
      "lies of hand the boding of the the world of the dangerous is by fai7s and remossadity.--bling of the useaven, life to be and just, mu:lyppenss\n",
      "and nifely thinks? it catuble,\n",
      "wever us man at the pratiss: over man: the sanging muchs any untarco,ued nasufies, wercomen.--at is love wiruep\" the bad man butte fraw was cos could\" inscurtive revoness even to a sufferss, and\n",
      "do and conjution. menfeven all, and among to the ret\n",
      "vavior\" betreat soul spose is is not w\n",
      "------ temperature: 1.2\n",
      " and among to the ret\n",
      "vavior\" betreat soul spose is is not would that adlading\n",
      "of these him bad hate--it -accsangly-somply forvess indearation of gation woprable of want is how has in many itmayi, us\n",
      "bess on? vow for supidedinicl over.\n",
      "\n",
      "\n",
      "riustanting itselvengerge. who be its onders\n",
      "morrers, umposing.\n",
      "\n",
      "shoochers\n",
      "ror--\n",
      "befevife\n",
      "youn,\n",
      "for we lass sumposowher condeesscisions, anowlered--accomden thai hir \"wilt, worthexs, it would pol\n",
      "muctly opile. hes berivadi\n",
      "epoch 2\n",
      "Epoch 1/1\n",
      "200278/200278 [==============================] - 238s 1ms/step - loss: 1.6314\n",
      "--- Generating with seed: \"timate product of the fear of truth, as artist-adoration\n",
      "and\"\n",
      "------ temperature: 0.2\n",
      "timate product of the fear of truth, as artist-adoration\n",
      "and the most decised and the something the sense of the sense of the sense of the sense of the souls and the something and the sere to the sense of the sense of the such and the sense the sense of the sense of the such and the something and the sense of the sense and pression that is the sere the sense the sense of the sense of the same the sense and percient\n",
      "and man and the sense of the sense in the\n",
      "------ temperature: 0.5\n",
      "sense and percient\n",
      "and man and the sense of the sense in the meative to the in farstand that a species and prejudice at the means to the souls to the freedom and secret\n",
      "and the been all is a such as a precised to a pathing and the such as a predivite and soul so, the polised and truth are religion, so the freeks of the such and which the species and the communsion of the certain this light in from this in the souls the free\n",
      "spiritually that enterial and at\n",
      "------ temperature: 1.0\n",
      " this in the souls the free\n",
      "spiritually that enterial and attointimous and perhans, the must\n",
      "man fickting tackly-feel out one moge id'stouated phecies of merelung-esoll, a spirit of higher\n",
      "sense of degreates.\n",
      "\n",
      "should evil\n",
      "emoontyness of symplate\n",
      "higher and man just here its artlable succecui=f aftercermaryn usy,\n",
      "just feels\n",
      "with of lect asd evince and orefuls too same re: takes of hitder supreder hy doctionable ender,\n",
      "by with up ele!  thin\n",
      "save. consirest b\n",
      "------ temperature: 1.2\n",
      "y doctionable ender,\n",
      "by with up ele!  thin\n",
      "save. consirest but but he dytriat\n",
      "has necessait, at foraggerang rongurereteg!sp and view tisk nocking the\n",
      "frakerble and imagodified: treeace, iroginiat to dispasestly only an as, \"fotrund new voutian claims-doys of sense\n",
      "but wouls care tauturines, new bids dono soem eventappines before xragily, the precise to very in sousphiencks, as almost virtuon\" of the \"efrece!\n",
      "\n",
      "4a. which afters,\n",
      "ab.\n",
      "treate to swine more clak\n",
      "epoch 3\n",
      "Epoch 1/1\n",
      "200278/200278 [==============================] - 235s 1ms/step - loss: 1.5464\n",
      "--- Generating with seed: \" isolde\"--what all these enjoy, and strive with mysterious\n",
      "a\"\n",
      "------ temperature: 0.2\n",
      " isolde\"--what all these enjoy, and strive with mysterious\n",
      "and such the surver of the to be the supposing the free specially the such the matter of the supposing the superficial that the superficial and the survers of the most present of the surver of the supposine the surver of the surmed and the supposine of the consequences of the supposing the surver to the surmination of the surming the such the surms of the consequences of the supposing the not and t\n",
      "------ temperature: 0.5\n",
      "the surms of the consequences of the supposing the not and the\n",
      "conscious been commoning of the the and constituon of the varity itself in its be the the speak and such the orman to the specie of believed only of the special so the religion of to the decesion of the supposing to be\n",
      "believe to be of the good the profound, has an itself not store of a conscious for the present of the appeth and religion of the surmity of the stright and the great or the good \n",
      "------ temperature: 1.0\n",
      "ion of the surmity of the stright and the great or the good manky--to the\n",
      "surficurly it, where son that, cherorherd knone! men latens to powit which is\n",
      "hearth them at varity of emotions, shown a streat.\n",
      "\n",
      "\n",
      "to the jess the or thor\n",
      "much\n",
      "its hackful, and ward will .glineal on apandardsing of\n",
      "this from themselves badoogial, this will for has more who present of quest ord\n",
      "holited mamings thereby\n",
      "mention, other,\n",
      "also for one ganty a seamer skeker ano do exercial \n",
      "------ temperature: 1.2\n",
      ", other,\n",
      "also for one ganty a seamer skeker ano do exercial most oldectoggentenize.? been,: when the elvead.--paesotion of these\n",
      "nevery has controlity to\n",
      "revelighd: flosty or prumentains'ablek concinedance of\n",
      "the vote\n",
      "displauty of\n",
      "\"roed up lone aconess at the higher class,\n",
      "by breacler! for as somate-falsces of lide to an aalsoxter loodspeded havonanes: more much it gebfuce snandiing. as that humanition: hervely happinate himhist whoce of imposspriblatiof w\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sys\n",
    "\n",
    "for epoch in range(1, 4):  ## Trains the model for 60 epochs\n",
    "    print('epoch', epoch)\n",
    "    # Fit the model for 1 epoch on the available training data\n",
    "    model.fit(x, y,\n",
    "              batch_size=128,\n",
    "              epochs=1)\n",
    "\n",
    "    # Select a text seed at random\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    generated_text = text[start_index: start_index + maxlen]\n",
    "    print('--- Generating with seed: \"' + generated_text + '\"')\n",
    "\n",
    "    for temperature in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print('------ temperature:', temperature)\n",
    "        sys.stdout.write(generated_text)\n",
    "\n",
    "        # We generate 400 characters\n",
    "        for i in range(400):\n",
    "            sampled = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(generated_text):\n",
    "                sampled[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(sampled, verbose=0)[0]\n",
    "            next_index = sample(preds, temperature)\n",
    "            next_char = chars[next_index]\n",
    "\n",
    "            generated_text += next_char\n",
    "            generated_text = generated_text[1:]\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  At epoch 60, the model has mostly converged, and the text starts to look significantly more coherent.\n",
    "\n",
    "**Here’s the result with temperature = 0.2 :**\n",
    "> `cheerfulness, friendliness and kindness of a heart are the sense of the\n",
    "spirit is a man with the sense of the sense of the world of the\n",
    "self-end and self-concerning the subjection of the strengthorixes--the\n",
    "subjection of the subjection of the subjection of the\n",
    "self-concerning the feelings in the superiority in the subjection of the\n",
    "subjection of the spirit isn't to be a man of the sense of the\n",
    "subjection and said to the strength of the sense of the`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here’s the result with temperature = 0.5 :**\n",
    "> `cheerfulness, friendliness and kindness of a heart are the part of the soul\n",
    "who have been the art of the philosophers, and which the one\n",
    "won't say, which is it the higher the and with religion of the frences.\n",
    "the life of the spirit among the most continuess of the\n",
    "strengther of the sense the conscience of men of precisely before enough\n",
    "presumption, and can mankind, and something the conceptions, the\n",
    "subjection of the sense and suffering and the`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here’s the result with temperature = 1.0 :**\n",
    "> `cheerfulness, friendliness and kindness of a heart are spiritual by the\n",
    "ciuture for the\n",
    "entalled is, he astraged, or errors to our you idstood--and it needs,\n",
    "to think by spars to whole the amvives of the newoatly, prefectly\n",
    "raals! it was\n",
    "name, for example but voludd atu-especity\"--or rank onee, or even all\n",
    "\"solett increessic of the world and\n",
    "implussional tragedy experience, transf, or insiderar,--must hast\n",
    "if desires of the strubction is be stronges`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ Analysis ] :\n",
    "\n",
    "+ **As you can see, a low temperature value results in extremely repetitive and predictable text, but local structure is highly realistic: in particular, all words (a word being a local pattern of characters) are real English words.** \n",
    "\n",
    "\n",
    "+ **With higher temperatures, the generated text becomes more interesting, surprising, even creative; it sometimes invents completely new words that sound somewhat plausible (such as eterned and troveration). With a high temperature, the local structure starts to break down, and most words look like semi-random strings of characters.** \n",
    "\n",
    "\n",
    "+ Without a doubt, 0.5 is the most interesting temperature for text generation in this specific setup. Always experiment with multiple sampling strategies! A clever balance between learned structure and random- ness is what makes generation interesting.\n",
    "\n",
    "\n",
    "+ Note that by training a bigger model, longer, on more data, you can achieve generated samples that look much more coherent and realistic than this one. \n",
    "\n",
    "\n",
    "+ But, of course, don’t expect to ever generate any meaningful text, other than by random chance: all you’re doing is sampling data from a statistical model of which characters come after which characters.\n",
    "\n",
    "\n",
    "+ **Language is a communication channel, and there’s a distinction between what communications are about and the statistical structure of the messages in which communications are encoded.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# < Exercise > :\n",
    "> ### 請將上述案例程式 (Keras/TensorFlow)，改寫成 TensorFlow 程式，並輸出結果。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
