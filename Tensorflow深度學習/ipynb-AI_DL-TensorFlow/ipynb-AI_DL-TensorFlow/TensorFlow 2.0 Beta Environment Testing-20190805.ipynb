{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 2.0 Beta Environment Testing\n",
    "\n",
    "###  *bigDataSpark Forum @ 2019/08/05*\n",
    "\n",
    "--------------------------------------\n",
    "+ ###  First, install `Anaconda 2019.07 for Windows` with `Python 3.7 version` https://www.anaconda.com/distribution/\n",
    "\n",
    "+ ### Then, run `TensorFlow 2.0 Beta (for CPU)` Setup on `Anaconda Prompt` in *Win10* :\n",
    ">###           1.  `conda create -n tf2`\n",
    ">###           2.  `pip install tensorflow=2.0.0-beta1`\n",
    "\n",
    "### [ Reference ]:\n",
    "+ TensorFlow.org, **\"Install TensorFlow with pip\"** https://www.tensorflow.org/install/pip\n",
    "+ 海萨, **\"Anaconda 安装tensorflow 2.0 报错解决办法\"** https://zhuanlan.zhihu.com/p/62031082\n",
    "+ khoa, **\"Install TensorFlow-gpu 2.0 Beta on Anaconda for Windows 10/Ubuntu\"** https://medium.com/@shaolinkhoa/install-tensorflow-gpu-2-0-alpha-on-anaconda-for-windows-10-ubuntu-ced099010b21\n",
    "+ TensorFlow.org, **\"Get Started with TensorFlow\"** https://www.tensorflow.org/tutorials/#get-started-with-tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ Content ]\n",
    "- [1. Testing TF 2.0](#TF2)\n",
    "- [2. How to run TensorFlow 1.x code on TF 2.0](#RunTF1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TF2'></a>\n",
    "## 1. Testing TF 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0805 20:18:42.118590 10288 deprecation.py:323] From C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 11s 176us/sample - loss: 0.2209 - accuracy: 0.9351\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 10s 170us/sample - loss: 0.0982 - accuracy: 0.9694\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 10s 173us/sample - loss: 0.0708 - accuracy: 0.9779\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 10s 174us/sample - loss: 0.0528 - accuracy: 0.9833\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 10s 173us/sample - loss: 0.0451 - accuracy: 0.9855\n",
      "10000/10000 [==============================] - 1s 69us/sample - loss: 0.0702 - accuracy: 0.9788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0702000554678496, 0.9788]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# The following code is adopted from \n",
    "# Tutorial document of TensorFlow.org \n",
    "# for testing TensorFlow 2.0 setup: \n",
    "#\n",
    "# \"Get Started with TensorFlow\" \n",
    "#  https://www.tensorflow.org/tutorials/#get-started-with-tensorflow\n",
    "# ---------------------------------------------\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "<a id='RunTF1'></a>\n",
    "## 2. How to run TensorFlow 1.x code on TF 2.0\n",
    "+ ### It is still possible to run 1.X code, unmodified (except for contrib), in TensorFlow 2.0:\n",
    "\n",
    "> ###  **`import tensorflow.compat.v1 as tf`**  \n",
    "> ###  **`tf.disable_v2_behavior()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-beta1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------\n",
    "### The following code is adopted for testing TensorFlow 2.0 setup from the reference below: \n",
    "\n",
    "+ Tom Hope, Yehezkel S. Resheff, and Itay Lieder, \"**Learning TensorFlow : A Guide to Building Deep Learning Systems**,\" Chapter 2 & 4, O'Reilly, 2017. https://goo.gl/iEmehh\n",
    "+ Download the code from GitHub : https://github.com/gigwegbe/Learning-TensorFlow\n",
    "---------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the MNIST dataset (from TensorFlow 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train = np.array([x_train[i].flatten() for i in range(len(x_train))])\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.array([x_test[i].flatten() for i in range(len(x_test))])\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0], y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(vec, vals=10):\n",
    "    n = len(vec)\n",
    "    out = np.zeros((n, vals))\n",
    "    out[range(n), vec] = 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = one_hot(y_train)\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = one_hot(y_test)\n",
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a computation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each Input Image, X, with 28*28 (= 784) pixels\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "\n",
    "# y_true : the training labeled dataset \n",
    "y_true = tf.placeholder(tf.float32,[None, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Weights & Biases for Nodes in All Hidden Layers \n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1) \n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape) \n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a Fully-Connected Deep Network\n",
    "def full_layer(inputs, size):\n",
    "    in_size = int(inputs.get_shape()[1]) \n",
    "    W = weight_variable([in_size, size]) \n",
    "    b = bias_variable([size])\n",
    "    return tf.add(tf.matmul(inputs, W), b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0805 20:19:38.125968 10288 deprecation.py:506] From <ipython-input-14-931f684597d4>:4: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "keep_prob = tf.placeholder(tf.float32)  \n",
    "\n",
    "# < Hidden Layer 1 >\n",
    "layer_1_drop = tf.nn.dropout(X, keep_prob=keep_prob)\n",
    "#   Activation Function : ReLU\n",
    "layer_1_Outputs = tf.nn.relu(full_layer(layer_1_drop, 256))\n",
    "\n",
    "# < Hidden Layer 2 >\n",
    "layer_2_drop = tf.nn.dropout(layer_1_Outputs, keep_prob=keep_prob)\n",
    "#   Activation Function : ReLU\n",
    "layer_2_Outputs = tf.nn.relu(full_layer(layer_2_drop, 128))  \n",
    "\n",
    "# < Output Layer >\n",
    "output_drop = tf.nn.dropout(layer_2_Outputs, keep_prob=keep_prob)\n",
    "# Without Activation Function\n",
    "y_pred = full_layer(output_drop, 10)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0805 20:19:38.264666 10288 deprecation.py:323] From <ipython-input-15-315e39f82a5d>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_pred, labels=y_true))\n",
    "gd_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "\n",
    "correct_mask = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y_true, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_mask, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launching the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(i, images, labels, batch_size):\n",
    "    i_start = (i * batch_size) % len(images)\n",
    "    x, y = images[i_start : i_start+batch_size], labels[i_start : i_start+batch_size]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000 : Loss = 0.2291, Accuracy = 0.930\n",
      "Step 2000 : Loss = 0.1149, Accuracy = 0.980\n",
      "Step 3000 : Loss = 0.1018, Accuracy = 0.990\n",
      "Step 4000 : Loss = 0.0792, Accuracy = 0.980\n",
      "Step 5000 : Loss = 0.0845, Accuracy = 0.970\n",
      "Step 6000 : Loss = 0.1002, Accuracy = 0.990\n",
      "Step 7000 : Loss = 0.0499, Accuracy = 0.990\n",
      "Step 8000 : Loss = 0.1032, Accuracy = 0.970\n",
      "\n",
      " Computing the test accuracy ...  \n",
      " [ Test  Accuracy ] : 0.9614999890327454\n",
      " [ Test Loss Score ] : 0.1306430548429489\n"
     ]
    }
   ],
   "source": [
    "NUM_STEPS = 8000\n",
    "MINIBATCH_SIZE = 100\n",
    "Display_Step = 1000\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(NUM_STEPS):\n",
    "        batch_xs, batch_ys = next_batch(i, x_train, y_train, MINIBATCH_SIZE)\n",
    "        sess.run(gd_step, feed_dict ={X: batch_xs, \n",
    "                                      y_true: batch_ys,\n",
    "                                      keep_prob: 0.5})\n",
    "        \n",
    "        if (i+1) % Display_Step == 0:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss_temp, accu_temp = sess.run([cross_entropy, accuracy], \n",
    "                                            feed_dict={X: batch_xs, \n",
    "                                                       y_true: batch_ys,\n",
    "                                                       keep_prob: 1.0})\n",
    "            print(\"Step \" + str(i+1).rjust(4) + \\\n",
    "                  \" : Loss = \" + \"{:.4f}\".format(loss_temp) + \\\n",
    "                  \", Accuracy = \" + \"{:.3f}\".format(accu_temp))\n",
    "\n",
    "    print(\"\\n Computing the test accuracy ... \", end = \" \")\n",
    "    \n",
    "    ##  ------------------------------------------------------------------\n",
    "    ##  Split the test procedure into 10 blocks of 1,000 images each. \n",
    "    ##  Doing this is important mostly for much larger datasets.\n",
    "    ##  ------------------------------------------------------------------\n",
    "    ##  mnist.test.images.shape : (10000, 784)\n",
    "    X_test = x_test.reshape(10, 1000, 784) \n",
    "    ##  mnist.test.labels.shape : (10000, 10)\n",
    "    Y_test = y_test.reshape(10, 1000, 10)   \n",
    "    \n",
    "    test_loss = np.mean([sess.run(cross_entropy,\n",
    "                                  feed_dict={X: X_test[i], \n",
    "                                             y_true: Y_test[i], \n",
    "                                             keep_prob: 1.0}) \n",
    "                                  for i in range(10)])\n",
    "    test_accu = np.mean([sess.run(accuracy,\n",
    "                                  feed_dict={X: X_test[i], \n",
    "                                             y_true: Y_test[i], \n",
    "                                             keep_prob: 1.0}) \n",
    "                                  for i in range(10)])\n",
    "    print(\"\\n [ Test  Accuracy ] : {}\".format(test_accu) +\n",
    "      \"\\n [ Test Loss Score ] : {}\".format(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
